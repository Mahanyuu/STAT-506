---
title: "ps2"
author: "mhanyu"
format:
  html:
    embed-resources: true
    code-fold: true
    code-summary: "Show the code"
---

[My Github](https://github.com/Mahanyuu/STAT-506/)

# Problem Set 2

## Problem 1

### 1.a.1 Play_dice_loop
```{r 1.a.1}

#' play_dice_loop: on a roll of 3 or 5, you win twice your roll. otherwise, you lose. The function is built on loop.
#' It costs 2 to play.
#' @param x the number of dice
#'
#' @return the total winnings (scores-2)

play_dice_loop <- function(x) {
  cost <- 2
  scores <- vector("numeric", length = x)
  random <- vector("numeric", length = x)
  for (i in 1:length(random)){
    random[i] = sample(1:6, 1)
    if (random[i]==3 | random[i]==5){
      scores[i] = random[i]*2
    }
  }
  sum <- 0
  for (i in seq_along(scores)){
    sum <- sum + scores[i]
  }
  
  winning <- sum-cost*x
  return(winning)
}

play_dice_loop(2)
  
```

### 1.a.2 Play_dice_vector
```{r 1.a.2}
#' play_dice_vector: The function is based on built-in R vectorized functions.
#' It costs 2 to play.
#' @param x the number of dice
#'
#' @return the total winnings (scores-2)
play_dice_vector <- function(x){
  cost <- 2
  random <- sample(1:6, x, replace = TRUE)
  scores <- random[random==3 | random==5]*2
  return(sum(scores)-cost*x)
}
play_dice_vector(6)
```

### 1.a.3 Play_dice_table
```{r 1.a.3}
#' play_dice_table: Using table to do the exercise
#' @param x the number of dice
#'
#' @return the total winnings (scores-2)
play_dice_table <- function(x){
  cost <- 2
  random <- sample(1:6, x, replace = TRUE)
  complete_table <- table(factor(random, levels = 1:6))
  scores <- unname(complete_table[3]*2*3 + complete_table[5]*2*5)
  winning <- scores-cost*x
  return (winning)
}
play_dice_vector(5)


```

### 1.a.4 Play_dice_apply
```{r 1.a.4}
play_dice_apply <- function(x){
  cost <- 2
  random <- matrix(sample(1:6, x, replace = TRUE), nrow =1)
  
  winning <- apply(random, 2, function(x){
    scores =0
    if (x==3 | x==5){
      scores <- scores+2*x
    }
    return(scores)
  })
  return(sum(winning)-cost*x)
}
play_dice_apply(5)
```

### 1.b
```{r 1.b}
for (i in c(3, 3000)){
  cat("play_dice_loop(",i,"): ", play_dice_loop(i),"\n")
  cat("play_dice_vector(",i,"): ", play_dice_vector(i),"\n")
  cat("play_dice_table(",i,"): ", play_dice_table(i),"\n")
  cat("play_dice_apply(",i,"): ",play_dice_apply(i),"\n")
}

```
### 1.c
```{r}
for (i in c(3, 3000)){
  set.seed(506)
  cat("play_dice_loop(",i,"): ", play_dice_loop(i),"\n")
  set.seed(506)
  cat("play_dice_vector(",i,"): ", play_dice_vector(i),"\n")
  set.seed(506)
  cat("play_dice_table(",i,"): ", play_dice_table(i),"\n")
  set.seed(506)
  cat("play_dice_apply(",i,"): ",play_dice_apply(i),"\n")
}
```
### 1.d
```{r 1.d}
library(microbenchmark)
microbenchmark(
  play_dice_loop(1000),
  play_dice_vector(1000),
  play_dice_table(1000),
  play_dice_apply(1000),
  play_dice_loop(100000),
  play_dice_vector(100000),
  play_dice_table(100000),
  play_dice_apply(100000)
)
```
summary:
Vector and table are both quicky. The vector is little faster than table. Vectorization always comes first because I use the sum and filter condition built-in R. Table also works well. Apply is the third fastest one. It works better than loop. But it is still very low. The loop works worst. This is because none of functions uses here.

### 1.e
```{r 1.e}
mean_billion_times <- play_dice_vector(1000000000)/1000000000
Expectation_play_dice <- 1/6*(10+6)-2
print(mean_billion_times)
print(Expectation_play_dice)
```
$$
E\_winnings=P(3) \times \operatorname{Payoff}(3)+P(5) \times \text { Payoff }(5)+P(\text { other }) \times \text { Payoff }(\text { other })
$$

$$
\begin{gathered}
E=\left(\frac{1}{6} \times 4\right)+\left(\frac{1}{6} \times 8\right)+\left(\frac{2}{3} \times(-2)\right) \\
E=\frac{4}{6}+\frac{8}{6}-\frac{4}{3} \ \approx 0.67
\end{gathered}
$$

Therefore, the expectation of dice game is equal to 0.66667, which is closed to the mean of billion times of Monte Carlo, which is 0.6666724. In this way, it is a fair game.

## Problem 2

### 2.a

```{r 2.a}
cars <- read.csv('data/cars.csv')
colnames(cars) <- c("height", "length", "width", "driveline", "engine_type", "hybrid", "forward_gears", "transmission", "city_mpg", "fuel_type", "highway_mpg", "classification", "ID", "make", "model_year", "year", "horsepower", "torque")
```

### 2.b

```{r 2.b}
cars_gasoline <- cars[cars["fuel_type"]=="Gasoline", ]
```

### 2.c
```{r 2.c}
#boxplot
boxplot(cars_gasoline$highway_mpg,main = "Highway MPG Boxplot", horizontal = TRUE)
#tranform
cars_gasoline$highway_mpg_log <- log(cars_gasoline$highway_mpg)

hist(
  cars_gasoline$highway_mpg_log,
  main = "The distribution of highway gas mileage",
  xlab = "highway_mpg",
  col = "lightblue"
)
qqnorm(cars_gasoline$highway_mpg_log)
qqline(cars_gasoline$highway_mpg_log, col="red")
boxplot(cars_gasoline$highway_mpg_log,main = "Highway LOG Boxplot", horizontal = TRUE)
#drop anomalies
outlier <- boxplot.stats(cars_gasoline$highway_mpg_log)$out
cars_highway_cleaned <- cars_gasoline[!cars_gasoline$highway_mpg_log %in% outlier, ]
boxplot(cars_highway_cleaned$highway_mpg_log,main = "Highway non-Anomaly LOG Boxplot", horizontal = TRUE)

hist(
  cars_highway_cleaned$highway_mpg_log,
  main = "The distribution of log highway gas mileage",
  xlab = "highway_mpg",
  col = "lightblue"
)
qqnorm(cars_highway_cleaned$highway_mpg_log)
qqline(cars_highway_cleaned$highway_mpg_log, col="red")
```
I choose to drop the anomalies by boxplot and log the highway gas mileage. This is because the number of highway gas mileage is scattered and large. After log, it will become more centralized so that more closed to normal distribution.

### 2.d
```{r 2.d}
cars_highway_cleaned$year_category <- as.factor(cars_highway_cleaned$year)
cars_highway_cleaned$torque_log <- log(cars_highway_cleaned$torque)
model_1 <- lm(highway_mpg_log ~ torque_log+horsepower+height+length+width+year_category,data = cars_highway_cleaned)
summary(model_1)

```
The result shows that torque has significantly negative effect on MPG on the highway at 0.1% level. I also choose to log the torque because torque is large and continuous data. And if the predictor of interest and dependent variable are logged, it is more clear to interpret.

For estimator, with the control of three dimensions, released year and the horsepower, when the torque increases by 100%, the MPG on the highway will significantly decrease by 66.5% at 0.1% level.

### 2.e

```{r}
library(interactions)
mod <- lm(highway_mpg_log ~ torque+horsepower+height+length+width+year_category+torque*horsepower,data = cars_highway_cleaned)
interact_plot(mod, pred = torque, modx = horsepower , at = list(year_category="2010"))
```
The default choice for different values in horsepower is mean, mean+1sd and mean-1sd. I think it makes sense because the mean provides a central tendency and 68% of data points lie in a normal distribution. Therefore, it is a reasonable choice because it can reflect common and most situation.

### 2.f

```{r 2.f}
design_matrix <- model.matrix(model_1, data = cars_highway_cleaned)
beta_hat <- solve(t(design_matrix)%*%design_matrix)%*%t(design_matrix)%*%cars_highway_cleaned$highway_mpg_log
beta_hat <- as.vector(beta_hat)
names(beta_hat) <- names(model_1$coefficients)
print(beta_hat)
print(model_1$coefficients)
all.equal(beta_hat, model_1$coefficients)

```
I did get the same result as prior.

